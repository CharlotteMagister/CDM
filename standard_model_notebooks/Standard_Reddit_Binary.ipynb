{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, dense_diff_pool\n",
    "import torch_explain as te\n",
    "from torch_explain.logic.nn import entropy\n",
    "from torch_explain.logic.metrics import test_explanation, complexity\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from scipy.spatial.distance import cdist\n",
    "from sympy import to_dnf, lambdify\n",
    "from sklearn.metrics.cluster import homogeneity_score, completeness_score\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import clustering_utils\n",
    "import data_utils\n",
    "import lens_utils\n",
    "import model_utils\n",
    "import persistence_utils\n",
    "import visualisation_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "DATASET_NAME = \"Reddit_Binary\"\n",
    "MODEL_NAME = f\"GCN for {DATASET_NAME}\"\n",
    "NUM_CLASSES = 2\n",
    "K = 30\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.8\n",
    "\n",
    "NUM_HIDDEN_UNITS = 40\n",
    "EPOCHS = 1000\n",
    "LR = 0.001\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "NUM_NODES_VIEW = 5\n",
    "NUM_EXPANSIONS = 4\n",
    "\n",
    "LAYER_NUM = 3\n",
    "LAYER_KEY = \"conv3\"\n",
    "\n",
    "visualisation_utils.set_rc_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, num_in_features, num_hidden_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        \n",
    "        self.conv0 = GCNConv(num_in_features, num_hidden_features)\n",
    "        self.conv1 = GCNConv(num_hidden_features, num_hidden_features)\n",
    "        self.conv2 = GCNConv(num_hidden_features, num_hidden_features)\n",
    "        self.conv3 = GCNConv(num_hidden_features, 10)\n",
    "        \n",
    "        self.pool = model_utils.Pool()\n",
    "\n",
    "        # linear layers\n",
    "        self.linear = nn.Linear(10, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv0(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        self.gnn_node_embedding = x\n",
    "        \n",
    "        x = self.pool(x, batch)\n",
    "        \n",
    "        self.gnn_graph_embedding = x\n",
    "\n",
    "        x = self.linear(x)\n",
    "                \n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(seed, path, load_pretrained=False):\n",
    "    persistence_utils.save_config(seed, DATASET_NAME, MODEL_NAME, NUM_CLASSES, K, TRAIN_TEST_SPLIT, NUM_HIDDEN_UNITS, EPOCHS, LR, NUM_NODES_VIEW, NUM_EXPANSIONS, LAYER_NUM, LAYER_KEY, path)\n",
    "        \n",
    "    # load data\n",
    "    graphs = data_utils.load_real_data(DATASET_NAME)\n",
    "    data = data_utils.prepare_real_data(graphs, TRAIN_TEST_SPLIT, BATCH_SIZE, DATASET_NAME)\n",
    "    train_loader, test_loader, full_train_loader, full_test_loader, full_loader, small_loader = data\n",
    "\n",
    "    # model training\n",
    "    model = GCN(graphs.num_node_features, NUM_HIDDEN_UNITS, graphs.num_classes)\n",
    "    \n",
    "    # register hooks to track activation\n",
    "    model = model_utils.register_hooks(model)\n",
    "\n",
    "    # train \n",
    "    train_acc, test_acc, train_loss, test_loss = model_utils.train_graph_class(model, train_loader, test_loader, full_loader, EPOCHS, LR, if_interpretable_model=False)\n",
    "    persistence_utils.persist_model(model, path, 'model.z')\n",
    "\n",
    "    visualisation_utils.plot_model_accuracy(train_acc, test_acc, MODEL_NAME, path)\n",
    "    visualisation_utils.plot_model_loss(train_loss, test_loss, MODEL_NAME, path)\n",
    "\n",
    "    # get model activations for complete dataset\n",
    "    train_data = next(iter(full_train_loader))\n",
    "    _ = model(train_data.x, train_data.edge_index, train_data.batch)\n",
    "    train_activation = model.gnn_node_embedding\n",
    "    \n",
    "    test_data = next(iter(full_test_loader))\n",
    "    _ = model(test_data.x, test_data.edge_index, test_data.batch)\n",
    "    test_activation = model.gnn_node_embedding\n",
    "    \n",
    "    activation = torch.vstack((train_activation, test_activation)).detach().numpy()\n",
    "    persistence_utils.persist_experiment(activation, path, 'activation.z')\n",
    "    \n",
    "    y = torch.cat((train_data.y, test_data.y))\n",
    "    expanded_train_y = data_utils.reshape_graph_to_node_data(train_data.y, train_data.batch)\n",
    "    expanded_test_y = data_utils.reshape_graph_to_node_data(test_data.y, test_data.batch)\n",
    "    expanded_y = torch.cat((expanded_train_y, expanded_test_y))\n",
    "    \n",
    "    train_mask = np.zeros(activation.shape[0], dtype=bool)\n",
    "    train_mask[:train_activation.shape[0]] = True\n",
    "    test_mask = ~train_mask\n",
    "    \n",
    "    offset = train_data.batch[-1] + 1\n",
    "    batch = torch.cat((train_data.batch, test_data.batch + offset))\n",
    "\n",
    "    # find centroids\n",
    "    kmeans_model = KMeans(n_clusters=K, random_state=seed)\n",
    "    kmeans_model = kmeans_model.fit(activation[train_mask])\n",
    "    used_centroid_labels = kmeans_model.predict(activation)\n",
    "    centroid_labels = np.sort(np.unique(used_centroid_labels))\n",
    "    centroids = kmeans_model.cluster_centers_\n",
    "    \n",
    "    persistence_utils.persist_experiment(kmeans_model, path, 'kmeans_model.z')\n",
    "    persistence_utils.persist_experiment(centroids, path, 'centroids.z')\n",
    "    persistence_utils.persist_experiment(centroid_labels, path, 'centroid_labels.z')\n",
    "    persistence_utils.persist_experiment(used_centroid_labels, path, 'used_centroid_labels.z')\n",
    "        \n",
    "    print(f\"Number of cenroids: {len(centroids)}\")\n",
    "    \n",
    "    # concept alignment\n",
    "    homogeneity = homogeneity_score(expanded_y, used_centroid_labels)\n",
    "    \n",
    "    # clustering efficency\n",
    "    completeness = completeness_score(expanded_y, used_centroid_labels)\n",
    "    \n",
    "    # calculate cluster sizing\n",
    "    cluster_counts = visualisation_utils.print_cluster_counts(used_centroid_labels)\n",
    "    \n",
    "    concept_metrics = [('homogeneity', homogeneity), ('completeness', completeness), ('cluster_count', cluster_counts)]\n",
    "    persistence_utils.persist_experiment(concept_metrics, path, 'concept_metrics.z')\n",
    "\n",
    "    print(f\"Concept homogeneity score: {homogeneity}\")\n",
    "    print(f\"Concept completeness score: {completeness}\")\n",
    "\n",
    "    # REDUCING DATA TO TRAINING SET\n",
    "    test_activation = test_activation.detach().numpy()\n",
    "    expanded_test_mask = data_utils.reshape_graph_to_node_data(test_mask, batch)\n",
    "    test_used_centroid_labels = kmeans_model.predict(test_activation)\n",
    "\n",
    "    print(\"Nodes to visualise \", expanded_test_mask.shape)\n",
    "    \n",
    "    # plot clustering\n",
    "    visualisation_utils.plot_clustering(seed, test_activation, expanded_test_y, centroids, centroid_labels, test_used_centroid_labels, MODEL_NAME, LAYER_NUM, path)\n",
    "    \n",
    "    # plot samples\n",
    "    edges_t = test_data.edge_index.transpose(0, 1).detach().numpy()\n",
    "    sample_graphs, sample_feat = visualisation_utils.plot_samples(None, test_activation, expanded_test_y, LAYER_NUM, len(centroids), \"Differential Clustering\", \"Raw\", NUM_NODES_VIEW, edges_t, NUM_EXPANSIONS, path, concepts=centroids)\n",
    "    persistence_utils.persist_experiment(sample_graphs, path, 'sample_graphs.z')\n",
    "    persistence_utils.persist_experiment(sample_feat, path, 'sample_feat.z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-fever",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run multiple times for confidence interval - seeds generated using Google's random number generator\n",
    "random_seeds = [42, 19, 76, 58, 92]\n",
    "\n",
    "for seed in random_seeds:\n",
    "    print(\"\\nSTART EXPERIMENT-----------------------------------------\\n\")\n",
    "    seed_everything(seed)\n",
    "    \n",
    "    path = os.path.join(\"..\", \"output\", \"Standard_\" + DATASET_NAME, f\"seed_{seed}\")\n",
    "    data_utils.create_path(path)\n",
    "\n",
    "    run_experiment(seed, path, load_pretrained=False)\n",
    "    \n",
    "    print(\"\\nEND EXPERIMENT-------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-reward",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
