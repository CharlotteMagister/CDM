{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quarterly-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "comprehensive-garlic",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/luciecharlottemagister/Documents/Cambridge/PhD/Projects/CEM/cem_env/lib/python3.9/site-packages/torch_sparse/_diag_cpu.so, 0x0006): Symbol not found: (__ZN3c106detail19maybe_wrap_dim_slowExxb)\n  Referenced from: '/Users/luciecharlottemagister/Documents/Cambridge/PhD/Projects/CEM/cem_env/lib/python3.9/site-packages/torch_sparse/_diag_cpu.so'\n  Expected in: '/Users/luciecharlottemagister/Documents/Cambridge/PhD/Projects/CEM/cem_env/lib/python3.9/site-packages/torch/lib/libc10.dylib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5629d677279b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_diff_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_explain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_explain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cambridge/PhD/Projects/CEM/cem_env/lib/python3.9/site-packages/torch_geometric/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cambridge/PhD/Projects/CEM/cem_env/lib/python3.9/site-packages/torch_geometric/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhetero_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtemporal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemporalData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cambridge/PhD/Projects/CEM/cem_env/lib/python3.9/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_sparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m from torch_geometric.data.storage import (BaseStorage, EdgeStorage,\n",
      "\u001b[0;32m~/Documents/Cambridge/PhD/Projects/CEM/cem_env/lib/python3.9/site-packages/torch_sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda_spec\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcpu_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         raise ImportError(f\"Could not find module '{library}_cpu' in \"\n",
      "\u001b[0;32m~/Documents/Cambridge/PhD/Projects/CEM/cem_env/lib/python3.9/site-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/luciecharlottemagister/Documents/Cambridge/PhD/Projects/CEM/cem_env/lib/python3.9/site-packages/torch_sparse/_diag_cpu.so, 0x0006): Symbol not found: (__ZN3c106detail19maybe_wrap_dim_slowExxb)\n  Referenced from: '/Users/luciecharlottemagister/Documents/Cambridge/PhD/Projects/CEM/cem_env/lib/python3.9/site-packages/torch_sparse/_diag_cpu.so'\n  Expected in: '/Users/luciecharlottemagister/Documents/Cambridge/PhD/Projects/CEM/cem_env/lib/python3.9/site-packages/torch/lib/libc10.dylib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, dense_diff_pool\n",
    "import torch_explain as te\n",
    "from torch_explain.logic.nn import entropy\n",
    "from torch_explain.logic.metrics import test_explanation, complexity\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from scipy.spatial.distance import cdist\n",
    "from sympy import to_dnf, lambdify\n",
    "from sklearn.metrics.cluster import homogeneity_score, completeness_score\n",
    "\n",
    "import clustering_utils\n",
    "import data_utils\n",
    "import lens_utils\n",
    "import model_utils\n",
    "import persistence_utils\n",
    "import visualisation_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "DATASET_NAME = \"BA_Shapes\"\n",
    "MODEL_NAME = f\"GCN for {DATASET_NAME}\"\n",
    "NUM_CLASSES = 4\n",
    "K = 10\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.8\n",
    "\n",
    "NUM_HIDDEN_UNITS = 10\n",
    "EPOCHS = 7000\n",
    "LR = 0.001\n",
    "\n",
    "RANDOM_STATE = 0\n",
    "\n",
    "NUM_NODES_VIEW = 5\n",
    "NUM_EXPANSIONS = 2\n",
    "\n",
    "LAYER_NUM = 3\n",
    "LAYER_KEY = \"conv3\"\n",
    "\n",
    "visualisation_utils.set_rc_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, num_in_features, num_hidden_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        \n",
    "        self.conv0 = GCNConv(num_in_features, num_hidden_features)\n",
    "        self.conv1 = GCNConv(num_hidden_features, num_hidden_features)\n",
    "        self.conv2 = GCNConv(num_hidden_features, num_hidden_features)\n",
    "        self.conv3 = GCNConv(num_hidden_features, num_hidden_features)\n",
    "#         self.conv4 = GCNConv(num_hidden_features, num_hidden_features)\n",
    "                \n",
    "        # linear layers\n",
    "        self.lens = torch.nn.Sequential(te.nn.EntropyLinear(num_hidden_features, 1, n_classes=num_classes))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv0(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "#         x = self.conv4(x, edge_index)\n",
    "#         x = F.leaky_relu(x)\n",
    "                \n",
    "        self.gnn_embedding = x\n",
    "        \n",
    "#         x = F.softmax(x, dim=-1)\n",
    "#         x = torch.div(x, torch.max(x, dim=-1)[0].unsqueeze(1))\n",
    "        x= F.sigmoid(x)\n",
    "        concepts = x\n",
    "        \n",
    "        x = self.lens(x)\n",
    "                \n",
    "        return concepts, x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(seed, path):\n",
    "    config = {'seed': seed,\n",
    "                       'dataset_name': DATASET_NAME,\n",
    "                       'model_name': MODEL_NAME,\n",
    "                       'num_classes': NUM_CLASSES,\n",
    "                       'k': K,\n",
    "                       'train_test_split': TRAIN_TEST_SPLIT,\n",
    "                       'num_hidden_units': NUM_HIDDEN_UNITS,\n",
    "                       'epochs': EPOCHS,\n",
    "                       'lr': LR,\n",
    "                       'num_nodes_view': NUM_NODES_VIEW,\n",
    "                       'num_expansions': NUM_EXPANSIONS,\n",
    "                       'layer_num': LAYER_NUM,\n",
    "                       'layer_key': LAYER_KEY\n",
    "                      }\n",
    "        \n",
    "    # load data\n",
    "    G, labels = data_utils.load_syn_data(DATASET_NAME)\n",
    "    data = data_utils.prepare_syn_data(G, labels, TRAIN_TEST_SPLIT)\n",
    "\n",
    "    # model training\n",
    "    model = GCN(data[\"x\"].shape[1], NUM_HIDDEN_UNITS, NUM_CLASSES)\n",
    "    \n",
    "    # register hooks to track activation\n",
    "    model = model_utils.register_hooks(model)\n",
    "    \n",
    "    # train \n",
    "    train_acc, test_acc, train_loss, test_loss = model_utils.train(model, data, EPOCHS, LR)\n",
    "        \n",
    "    visualisation_utils.plot_model_accuracy(train_acc, test_acc, MODEL_NAME, path)\n",
    "    visualisation_utils.plot_model_loss(train_loss, test_loss, MODEL_NAME, path)\n",
    "    \n",
    "    x = data[\"x\"]\n",
    "    edges = data['edges']\n",
    "    edges_t = data['edge_list'].numpy()\n",
    "    y = data[\"y\"]\n",
    "    train_mask = data[\"train_mask\"]\n",
    "    test_mask = data[\"test_mask\"]\n",
    "    \n",
    "    # get model activations for complete dataset\n",
    "    concepts, _ = model(x, edges)\n",
    "    activation = torch.squeeze(model_utils.activation_list[LAYER_KEY]).detach().numpy()\n",
    "    \n",
    "    # find centroids\n",
    "    centroids, centroid_labels, used_centroid_labels = clustering_utils.find_centroids(activation, concepts, y)\n",
    "    print(f\"Number of cenroids: {len(centroids)}\")\n",
    "    \n",
    "    # plot concept heatmaps\n",
    "    visualisation_utils.plot_concept_heatmap(centroids, activation, y, used_centroid_labels, MODEL_NAME, LAYER_NUM, path)\n",
    "    \n",
    "    # concept alignment\n",
    "    homogeneity = homogeneity_score(y, used_centroid_labels)\n",
    "    # clustering efficency\n",
    "    completeness = completeness_score(y, used_centroid_labels)\n",
    "    \n",
    "    print(f\"Concept homogeneity score: {homogeneity}\")\n",
    "    print(f\"Concept completeness score: {completeness}\")\n",
    "    \n",
    "    # generate explanations\n",
    "    \n",
    "#     print(concepts)\n",
    "#     print(y)\n",
    "    explanations = lens_utils.explain_classes(model, concepts, y, train_mask, test_mask)\n",
    "    \n",
    "    # plot clustering\n",
    "    visualisation_utils.plot_clustering(seed, activation, y, centroids, centroid_labels, used_centroid_labels, MODEL_NAME, LAYER_NUM, path)\n",
    "    \n",
    "    # calculate cluster sizing\n",
    "    cluster_counts = visualisation_utils.print_cluster_counts(used_centroid_labels)\n",
    "\n",
    "    # plot samples\n",
    "    sample_graphs, sample_feat = visualisation_utils.plot_samples(None, activation, y, LAYER_NUM, len(centroids), \"Differential Clustering\", \"Raw\", NUM_NODES_VIEW, edges_t, NUM_EXPANSIONS, path, concepts=centroids)\n",
    "    \n",
    "    # dump data\n",
    "    persistence_utils.persist_experiment(config, path, 'config.z')\n",
    "    persistence_utils.persist_experiment(data, path,'data.z')\n",
    "    \n",
    "    persistence_utils.persist_model(model, path, 'model.z')\n",
    "    \n",
    "    persistence_utils.persist_experiment(concepts, path, 'concepts.z')\n",
    "    persistence_utils.persist_experiment(model_utils.activation_list, path, 'activation_list.z')\n",
    "    persistence_utils.persist_experiment(centroids, path, 'centroids.z')\n",
    "    persistence_utils.persist_experiment(centroid_labels, path, 'centroid_labels.z')\n",
    "    persistence_utils.persist_experiment(used_centroid_labels, path, 'used_centroid_labels.z')\n",
    "    \n",
    "    concept_metrics = [('homogeneity', homogeneity), ('completeness', completeness), ('cluster_count', cluster_counts)]\n",
    "    persistence_utils.persist_experiment(concept_metrics, path, 'concept_metrics.z')\n",
    "    persistence_utils.persist_experiment(explanations, path, 'explanations.z')\n",
    "    persistence_utils.persist_experiment(sample_graphs, path, 'sample_graphs.z')\n",
    "    persistence_utils.persist_experiment(sample_feat, path, 'sample_feat.z')\n",
    "    \n",
    "    # clean up\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-fever",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run multiple times for confidence interval - seeds generated using Google's random number generator\n",
    "random_seeds = [42]\n",
    "\n",
    "for seed in random_seeds:\n",
    "    print(\"\\nSTART EXPERIMENT-----------------------------------------\\n\")\n",
    "    seed_everything(seed)\n",
    "    \n",
    "    path = os.path.join(\"..\", \"output\", DATASET_NAME + \"_sigmoid_test\", f\"seed_{seed}\")\n",
    "    data_utils.create_path(path)\n",
    "\n",
    "    run_experiment(seed, path)\n",
    "    \n",
    "    print(\"\\nEND EXPERIMENT-------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-reward",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cem_env",
   "language": "python",
   "name": "cem_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
